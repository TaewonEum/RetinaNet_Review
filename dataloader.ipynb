{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1af6aa-6ed4-4767-8203-060819cf633a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataloader\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.color\n",
    "import skimage\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec84906e-a5b3-4191-afb4-2d19f6d6f087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path='C:/Users/user/Desktop/all_img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f41dadf1-de74-432f-80f7-384b55596538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB_BI'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coco=COCO(os.path.join(path+'/'+'train'+'/'+'annotations'+'/'+'instances_'+'train2017'+'.json'))\n",
    "#class_1=coco.getCatIds()\n",
    "#coco.loadCats(3)[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637b3634-498d-412c-94da-49051d198406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes=['Larva','disease'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6a0ffd-0345-4619-a062-b9dc21ab30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coco형식의 데이터 셋 불러오기\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self,data_dir,set_name,transform=None): #source code에는 set_name=train2017로 고정되어있음\n",
    "        self.data_dir=data_dir #train,valid, test까지의 경로,O\n",
    "        self.set_name=set_name #train2017, val2017->train까지의 경로일 시, test경로일시->test2017,O\n",
    "        self.transform=transform #이미지 정규화, 텐서변환 등\n",
    "        #coco dataset load를 위해 self.set_name작성해줌->추후 불러올때 train,val 분할 가능\n",
    "        self.coco=COCO(os.path.join(self.data_dir+'/'+'annotations'+'/'+'instances_'+self.set_name+'.json')) #라벨링 파일로 cocodataset load\n",
    "        #이미지 고유 아이디, class 저장\n",
    "        self.image_ids=self.coco.getImgIds() #이미지 전체 인덱스를 저장 0,,,,,N까지의 인덱스 저장\n",
    "        #self.imgInfo=self.coco.loadImgs(self.image_ids)\n",
    "        self.load_classes() #self.classes라는 인스턴스 변수를 생성, coco데이터셋에서 사용된 클래스의 이름을 이 변수에 저장함, 딕셔너리를 출력하면 데이터셋에서 사용된\n",
    "        # 모든 클래스 이름 확인 가능\n",
    "        \n",
    "    def load_classes(self):\n",
    "        #Load class names(name->label)\n",
    "        categories = self.coco.loadCats(self.coco.getCatIds()) #클래스별 고유 아이디, name, supercategory값 저장,[{'id': 0, 'name': 'disease', 'supercategory': 'none'},\n",
    "        categories.sort(key=lambda x: x['id']) #id순 정리\n",
    "        self.classes={} #빈 딕셔너리 생성\n",
    "        self.coco_labels={} #라벨값을 담을 빈 딕셔너리 생성\n",
    "        self.coco_labels_inverse={} #라벨값 내림차순 정렬 빈 딕셔너리 생성인듯 밑에\n",
    "        \n",
    "        for c in categories:\n",
    "            self.coco_labels[len(self.classes)]=c['id'] #self.coco_labels에 0~label마지막 id값 저장,  {0:0,1:1}.....\n",
    "            self.coco_labels_inverse[c['id']]=len(self.classes) #labels와 같음, ex) id=0->len=0, id=1->len=1\n",
    "            self.classes[c['name']]=len(self.classes) #disease:13......\n",
    "        self.labels={}\n",
    "        \n",
    "        for key,value in self.classes.items():\n",
    "            self.labels[value]=key #13:disease....\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids) #전체 이미지 장수개수 만큼 리턴\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=self.load_image(idx) #load_image함수는 밑에 있음\n",
    "        annot=self.load_annotations(idx) #load_annotations함수는 밑에 있음\n",
    "        sample={'img':img,'annot':annot} #이미지 배열값, x,y,x1,x2값\n",
    "        #print(sample)\n",
    "        if self.transform:\n",
    "            sample=self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def load_image(self,image_index): #image_index를 넣어주면 실행됨\n",
    "        #img=None\n",
    "        image_info=self.coco.loadImgs(self.image_ids[image_index])[0] #id, filename,width,height 추출\n",
    "        path=os.path.join(self.data_dir,'images',image_info['file_name'])\n",
    "        img=skimage.io.imread(path)\n",
    "        \n",
    "        #클래스 폴더가 나누어진 경우 아래의 코드 주석 풀고 실행\n",
    "        # try:\n",
    "        #     if 'LA_NA' in image_info['file_name']:\n",
    "        #         path=os.path.join(self.data_dir,'images',classes[0],image_info['file_name'])\n",
    "        #         img=skimage.io.imread(path) #이미지 numpy변환\n",
    "        #     elif 'AA_NA' in image_info['file_name']:\n",
    "        #         path=os.path.join(self.data_dir,'images',classes[1],image_info['file_name'])\n",
    "        #         img=skimage.io.imread(path) #이미지 numpy변환\n",
    "        #     else:\n",
    "        #         raise FileNotFoundError('Image file not found.')\n",
    "        # except FileNotFoundError:\n",
    "        #     raise FileNotFoundError(f\"Image file not found for image index {image_index}.\")\n",
    "                \n",
    "        if len(img.shape)==2: #흑백 이미지 (480,480)이런식\n",
    "            img=skimage.color.gray2rgb(img) #흑백 이미지 컬러이미지 변환\n",
    "            \n",
    "        return img.astype(np.float32)/255 #이미지 배열값\n",
    "    \n",
    "    def load_annotations(self,image_index):\n",
    "        annotations_ids=self.coco.getAnnIds(self.image_ids[image_index],iscrowd=False) #iscrowd=False->각각의 객체를 인식하기 위해, 이미지안에 객체 인덱스\n",
    "        annotations=np.zeros((0,5)) #class,x,y,width,height 넣어주기 위함 빈 배열임\n",
    "        \n",
    "        if len(annotations_ids)==0: #객체가 없으면 함수 실행 종료\n",
    "            return annotations\n",
    "        \n",
    "        coco_annotations=self.coco.loadAnns(annotations_ids) #id, image_id.category_id, bbox........\n",
    "        for idx, a in enumerate(coco_annotations): #idx=index, a=id,image_id,category_id,bbox\n",
    "            if a['bbox'][2] < 1 or a['bbox'][3] <1: #width, height가 no width or no height\n",
    "                continue\n",
    "                \n",
    "            annotation=np.zeros((1,5)) #[0,0,0,0,0]\n",
    "            annotation[0,:4]=a['bbox'] #1,2,3,4번째에 각각 x,y,width,height\n",
    "            annotation[0,4]=self.coco_label_to_label(a['category_id']) #마지막에는 class고유값\n",
    "            annotations=np.append(annotations,annotation,axis=0) #배열 append\n",
    "            \n",
    "        # transform from [x,y,w,h] to [x1,y1, x2, y2]\n",
    "        annotations[:,2]=annotations[:,0]+annotations[:,2] #x2=x+width\n",
    "        annotations[:,3]=annotations[:,1]+annotations[:,3] #y2=y+height\n",
    "        \n",
    "        return annotations #[x1,y1,x2,y2,category_id]\n",
    "    \n",
    "    def coco_label_to_label(self,coco_label):\n",
    "        return self.coco_labels_inverse[coco_label]\n",
    "    \n",
    "    def label_to_coco_label(self,label):\n",
    "        return self.coco_labels[label]\n",
    "        \n",
    "    def image_aspect_ratio(self,image_index):\n",
    "        image=self.coco.loadImgs(self.image_ids[image_index])[0] #dictionary 형태id' {0,'license': 1,'file_name': '01_1_R_AB_LI_20220715_06_0204_jpg.rf.8860e7904cb6a8f0a601e32d63ad3e24.jpg','height': 480,'width': 480,\n",
    "        return float(image['width']) / float(image['height'])\n",
    "        \n",
    "        \n",
    "    def num_classes(self):\n",
    "        return len(self.classes)\n",
    "    \n",
    "    def class_list_final(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cdf32b-5674-4c19-b637-e91f6ea0b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coco_testdata(Dataset):\n",
    "    def __init__(self,data_dir,set_name,transform=None): \n",
    "        self.data_dir=data_dir #train,valid, test까지의 경로,O\n",
    "        self.set_name=set_name #train2017, val2017->train까지의 경로일 시, test경로일시->test2017,O\n",
    "        self.transform=transform #이미지 정규화, 텐서변환 등\n",
    "        #coco dataset load를 위해 self.set_name작성해줌->추후 불러올때 train,val 분할 가능\n",
    "        self.coco=COCO(os.path.join(self.data_dir+'/'+'annotations'+'/'+'instances_'+self.set_name+'.json')) #라벨링 파일로 cocodataset load\n",
    "        #이미지 고유 아이디, class 저장\n",
    "        self.image_ids=self.coco.getImgIds() #이미지 전체 인덱스를 저장 0,,,,,N까지의 인덱스 저장\n",
    "        #self.imgInfo=self.coco.loadImgs(self.image_ids)\n",
    "        self.load_classes() #self.classes라는 인스턴스 변수를 생성, coco데이터셋에서 사용된 클래스의 이름을 이 변수에 저장함, 딕셔너리를 출력하면 데이터셋에서 사용된\n",
    "        # 모든 클래스 이름 확인 가능\n",
    "        \n",
    "    def load_classes(self):\n",
    "        #Load class names(name->label)\n",
    "        categories = self.coco.loadCats(self.coco.getCatIds()) #클래스별 고유 아이디, name, supercategory값 저장,[{'id': 0, 'name': 'disease', 'supercategory': 'none'},\n",
    "        categories.sort(key=lambda x: x['id']) #id순 정리\n",
    "        self.classes={} #빈 딕셔너리 생성\n",
    "        self.coco_labels={} #라벨값을 담을 빈 딕셔너리 생성\n",
    "        self.coco_labels_inverse={} #라벨값 내림차순 정렬 빈 딕셔너리 생성인듯 밑에\n",
    "        \n",
    "        for c in categories:\n",
    "            self.coco_labels[len(self.classes)]=c['id'] #self.coco_labels에 0~label마지막 id값 저장,  {0:0,1:1}.....\n",
    "            self.coco_labels_inverse[c['id']]=len(self.classes) #labels와 같음, ex) id=0->len=0, id=1->len=1\n",
    "            self.classes[c['name']]=len(self.classes) #disease:13......\n",
    "        self.labels={}\n",
    "        \n",
    "        for key,value in self.classes.items():\n",
    "            self.labels[value]=key #13:disease....\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids) #전체 이미지 장수개수 만큼 리턴\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=self.load_image(idx) #load_image함수는 밑에 있음\n",
    "        annot=self.load_annotations(idx) #load_annotations함수는 밑에 있음\n",
    "        img_name=self.load_image_idx(idx)\n",
    "        img_name={'filename':img_name}\n",
    "        sample={'img':img,'annot':annot} #이미지 배열값, x,y,x1,x2값\n",
    "        #print(sample)\n",
    "        if self.transform:\n",
    "            sample=self.transform(sample)\n",
    "        \n",
    "        return sample, img_name\n",
    "    \n",
    "    def load_image_idx(self,image_index):\n",
    "        image_ids_test=self.coco.loadImgs(image_index)[0]['file_name']\n",
    "        return image_ids_test\n",
    "    \n",
    "    def load_image(self,image_index): #image_index를 넣어주면 실행됨\n",
    "        #img=None\n",
    "        image_info=self.coco.loadImgs(self.image_ids[image_index])[0] #id, filename,width,height 추출\n",
    "        path=os.path.join(self.data_dir,'images',image_info['file_name'])\n",
    "        img=skimage.io.imread(path)\n",
    "        # try:\n",
    "        #     if 'LA_NA' in image_info['file_name']:\n",
    "        #         path=os.path.join(self.data_dir,'images',classes[0],image_info['file_name'])\n",
    "        #         img=skimage.io.imread(path) #이미지 numpy변환\n",
    "        #     elif 'AA_NA' in image_info['file_name']:\n",
    "        #         path=os.path.join(self.data_dir,'images',classes[1],image_info['file_name'])\n",
    "        #         img=skimage.io.imread(path) #이미지 numpy변환\n",
    "        #     else:\n",
    "        #         raise FileNotFoundError('Image file not found.')\n",
    "        # except FileNotFoundError:\n",
    "        #     raise FileNotFoundError(f\"Image file not found for image index {image_index}.\")\n",
    "        \n",
    "        if len(img.shape)==2: #흑백 이미지 (480,480)이런식\n",
    "            img=skimage.color.gray2rgb(img) #흑백 이미지 컬러이미지 변환\n",
    "            \n",
    "        return img.astype(np.float32)/255 #이미지 배열값\n",
    "    \n",
    "    def load_annotations(self,image_index):\n",
    "        annotations_ids=self.coco.getAnnIds(self.image_ids[image_index],iscrowd=False) #iscrowd=False->각각의 객체를 인식하기 위해, 이미지안에 객체 인덱스\n",
    "        annotations=np.zeros((0,5)) #class,x,y,width,height 넣어주기 위함 빈 배열임\n",
    "        \n",
    "        if len(annotations_ids)==0: #객체가 없으면 함수 실행 종료\n",
    "            return annotations\n",
    "        \n",
    "        coco_annotations=self.coco.loadAnns(annotations_ids) #id, image_id.category_id, bbox........\n",
    "        for idx, a in enumerate(coco_annotations): #idx=index, a=id,image_id,category_id,bbox\n",
    "            if a['bbox'][2] < 1 or a['bbox'][3] <1: #width, height가 no width or no height\n",
    "                continue\n",
    "                \n",
    "            annotation=np.zeros((1,5)) #[0,0,0,0,0]\n",
    "            annotation[0,:4]=a['bbox'] #1,2,3,4번째에 각각 x,y,width,height\n",
    "            annotation[0,4]=self.coco_label_to_label(a['category_id']) #마지막에는 class고유값\n",
    "            annotations=np.append(annotations,annotation,axis=0) #배열 append\n",
    "            \n",
    "        # transform from [x,y,w,h] to [x1,y1, x2, y2]\n",
    "        annotations[:,2]=annotations[:,0]+annotations[:,2] #x2=x+width\n",
    "        annotations[:,3]=annotations[:,1]+annotations[:,3] #y2=y+height\n",
    "        \n",
    "        return annotations #[x1,y1,x2,y2,category_id]\n",
    "    \n",
    "    def coco_label_to_label(self,coco_label):\n",
    "        return self.coco_labels_inverse[coco_label]\n",
    "    \n",
    "    def label_to_coco_label(self,label):\n",
    "        return self.coco_labels[label]\n",
    "        \n",
    "    def image_aspect_ratio(self,image_index):\n",
    "        image=self.coco.loadImgs(self.image_ids[image_index])[0] #dictionary 형태id' {0,'license': 1,'file_name': '01_1_R_AB_LI_20220715_06_0204_jpg.rf.8860e7904cb6a8f0a601e32d63ad3e24.jpg','height': 480,'width': 480,\n",
    "        return float(image['width']) / float(image['height'])\n",
    "        \n",
    "        \n",
    "    def num_classes(self):\n",
    "        return len(self.classes)\n",
    "    \n",
    "    def class_list_final(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994e0b1-091a-4fd8-8ba8-b2ff347340f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater_test(data):\n",
    "    # img=sample['img'], annots=sample['annots'], scales=sample['scale']\n",
    "    imgs=[s[0]['img'] for s in data] #이미지\n",
    "    annots=[s[0]['annot'] for s in data] #annoation\n",
    "    filename=[z['filename'] for s,z in data]\n",
    "    scales=[s[0]['scale'] for s in data] #scale\n",
    "    widths = [int(s.shape[0]) for s in imgs] #이미지 넓이\n",
    "    heights = [int(s.shape[1]) for s in imgs] #이미지 높이\n",
    "    batch_size = len(imgs) #배치사이즈\n",
    "\n",
    "    max_width = np.array(widths).max() #max 이미지 넓이\n",
    "    max_height = np.array(heights).max() #max 이미지 높이\n",
    "\n",
    "    padded_imgs = torch.zeros(batch_size, max_width, max_height, 3) #max에 맞추어 0으로 패딩한 torch Tensor\n",
    "\n",
    "    for i in range(batch_size):#batch당 이미지와 패딩Tensor 이미지 사이즈에 맞게 값을 넣어줌\n",
    "        img = imgs[i]\n",
    "        padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = img\n",
    "\n",
    "    max_num_annots = max(annot.shape[0] for annot in annots)\n",
    "    \n",
    "    if max_num_annots > 0:\n",
    "\n",
    "        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\n",
    "\n",
    "        if max_num_annots > 0:\n",
    "            for idx, annot in enumerate(annots):\n",
    "                #print(annot.shape)\n",
    "                if annot.shape[0] > 0:\n",
    "                    annot_padded[idx, :annot.shape[0], :] = annot\n",
    "    else:\n",
    "        annot_padded = torch.ones((len(annots), 1, 5)) * -1\n",
    "\n",
    "\n",
    "    padded_imgs = padded_imgs.permute(0, 3, 1, 2)\n",
    "\n",
    "    return {'img': padded_imgs, 'annot': annot_padded, 'scale': scales, 'filename':filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f88abb8-a506-4c77-9228-6362b5974d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater(data):\n",
    "    # img=sample['img'], annots=sample['annots'], scales=sample['scale']\n",
    "    imgs=[s['img'] for s in data] #이미지\n",
    "    annots=[s['annot'] for s in data] #annoation\n",
    "    #filename=[s['filename'] for s in data]\n",
    "    scales=[s['scale'] for s in data] #scale\n",
    "    widths = [int(s.shape[0]) for s in imgs] #이미지 넓이\n",
    "    heights = [int(s.shape[1]) for s in imgs] #이미지 높이\n",
    "    batch_size = len(imgs) #배치사이즈\n",
    "\n",
    "    max_width = np.array(widths).max() #max 이미지 넓이\n",
    "    max_height = np.array(heights).max() #max 이미지 높이\n",
    "\n",
    "    padded_imgs = torch.zeros(batch_size, max_width, max_height, 3) #max에 맞추어 0으로 패딩한 torch Tensor\n",
    "\n",
    "    for i in range(batch_size):#batch당 이미지와 패딩Tensor 이미지 사이즈에 맞게 값을 넣어줌\n",
    "        img = imgs[i]\n",
    "        padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = img\n",
    "\n",
    "    max_num_annots = max(annot.shape[0] for annot in annots)\n",
    "    \n",
    "    if max_num_annots > 0:\n",
    "\n",
    "        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\n",
    "\n",
    "        if max_num_annots > 0:\n",
    "            for idx, annot in enumerate(annots):\n",
    "                #print(annot.shape)\n",
    "                if annot.shape[0] > 0:\n",
    "                    annot_padded[idx, :annot.shape[0], :] = annot\n",
    "    else:\n",
    "        annot_padded = torch.ones((len(annots), 1, 5)) * -1\n",
    "\n",
    "\n",
    "    padded_imgs = padded_imgs.permute(0, 3, 1, 2)\n",
    "\n",
    "    return {'img': padded_imgs, 'annot': annot_padded, 'scale': scales}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37dd555-e406-4d89-9337-c0dc931dc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image resize부분\n",
    "class Resizer(object): #ndarrays->Tensor\n",
    "    def __call__(self,sample,min_side=480,max_side=640): #min side, max side는 해당값으로 고정시켜주기\n",
    "        image, annots =sample['img'], sample['annot'] #Cocodataset함수를 실행하며 sample변수가 생성됨 그것을 사용\n",
    "        rows, cols, cns=image.shape #width, height, channels\n",
    "        smallest_side=min(rows,cols) #너비, 높이 최소값\n",
    "        # rescale the image->min_side/smallest_side->이미지를 최소한의 크기로 조정하기 위함\n",
    "        scale=min_side/smallest_side #608/실제 가장 작은 값->이를 통해 이미지와 바운딩박스를 적절한 비율로 조정함\n",
    "        #실제 max_side값 구하기\n",
    "        largest_side=max(rows,cols) #가장 큰 너비, 혹은 높이\n",
    "        \n",
    "        if largest_side * scale > max_side: #max side보다 클 경우\n",
    "            scale=max_side/largest_side #scale값 조정\n",
    "            \n",
    "        #resize the image with the computed scale-> scale값을 사용하여 이미지 Resize\n",
    "        image=skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))\n",
    "        rows, cols, cns=image.shape #Resize한 row, col, cns\n",
    "        #1024 side는 32x32 사이즈임->32행 32열중 어떠한 열을 padding할지 정하기 위해 32-rows%32하여 padding사이즈 구함\n",
    "        pad_w=32-rows%32 #만약 489라면 9개의 행에 0을 추가하는 패딩\n",
    "        pad_h=32-cols%32\n",
    "        \n",
    "        new_image=np.zeros((rows+pad_w,cols+pad_h,cns)).astype(np.float32)\n",
    "        new_image[:rows,:cols,:]=image.astype(np.float32)\n",
    "        \n",
    "        annots[:,:4]*=scale #scale값 곱해주기\n",
    "        return {'img':torch.from_numpy(new_image),'annot':torch.from_numpy(annots),'scale':scale}# from_numpy->numpy배열 Tensor로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd90622-7437-4e6a-9e32-95cdacd71c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmenter(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, flip_x=0.5):\n",
    "\n",
    "        if np.random.rand() < flip_x:\n",
    "            image, annots = sample['img'], sample['annot']\n",
    "            image = image[:, ::-1, :]\n",
    "\n",
    "            rows, cols, channels = image.shape\n",
    "\n",
    "            x1 = annots[:, 0].copy()\n",
    "            x2 = annots[:, 2].copy()\n",
    "            \n",
    "            x_tmp = x1.copy()\n",
    "\n",
    "            annots[:, 0] = cols - x2\n",
    "            annots[:, 2] = cols - x_tmp\n",
    "\n",
    "            sample = {'img': image, 'annot': annots}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e11936-b752-45bd-9544-d92bcb2c8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mean = np.array([[[0.485, 0.456, 0.406]]])\n",
    "        self.std = np.array([[[0.229, 0.224, 0.225]]])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        return {'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots}\n",
    "\n",
    "class UnNormalizer(object):\n",
    "    def __init__(self, mean=None, std=None):\n",
    "        if mean == None:\n",
    "            self.mean = [0.485, 0.456, 0.406]\n",
    "        else:\n",
    "            self.mean = mean\n",
    "        if std == None:\n",
    "            self.std = [0.229, 0.224, 0.225]\n",
    "        else:\n",
    "            self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6729f69d-806c-4f80-8e0a-a81c83ef9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AspectRatioBasedSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, batch_size, drop_last):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.groups = self.group_images()\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.groups)\n",
    "        for group in self.groups:\n",
    "            yield group\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.data_source) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.data_source) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def group_images(self):\n",
    "        # determine the order of the images\n",
    "        order = list(range(len(self.data_source)))\n",
    "        order.sort(key=lambda x: self.data_source.image_aspect_ratio(x))\n",
    "\n",
    "        # divide into groups, one group = one batch\n",
    "        return [[order[x % len(order)] for x in range(i, i + self.batch_size)] for i in range(0, len(order), self.batch_size)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
