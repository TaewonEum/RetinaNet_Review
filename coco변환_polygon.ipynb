{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7a485b-e3f9-42b8-8be3-bedcf932dbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataloader\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.color\n",
    "import skimage\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711a116d-5d2f-4d63-bc31-d13b4cfef7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbda8e9f-f6d0-46ab-94f2-6e9968d39a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test data 경로\n",
    "path='C:/Users/user/Desktop/sample_flexink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d10fe8-b5a3-434a-8ac3-a3dd3a60b0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new data path\n",
    "save_path='C:/Users/user/Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a25b81-0854-4d57-a397-26cef6febbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes=['halibut'] #탐지할 클래스명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5c22ee-a7d1-446c-9b2c-50cf90c2b30c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_원천데이터', '02_라벨링데이터']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1430f8-081b-48d4-b65c-eaeb7d9f694f",
   "metadata": {},
   "source": [
    "# dataset 경로 저장(전체 데이터 저장 후 TVT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d502f50b-7b70-49bd-be47-de3737d9b0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 파일 리스트화\n",
    "# img_list=[]\n",
    "# lab_list=[]\n",
    "\n",
    "\n",
    "# img_path=glob.glob(path+'/'+'01_원천데이터'+'/*')\n",
    "# lab_path=glob.glob(path+'/'+'02_라벨링데이터'+'/*')\n",
    "# for i in range(len(img_path)):\n",
    "#     img_path[i]=img_path[i].replace('\\\\','/')\n",
    "#     lab_path[i]=lab_path[i].replace('\\\\','/')\n",
    "# img_list.extend(img_path)\n",
    "# lab_list.extend(lab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3992c206-51d1-4503-abc6-29ba4745e262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(img_list)) #이미지 파일명\n",
    "# print(len(lab_list)) #라벨링 파일명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7ef8bb-f886-48c0-8b52-4579c2db9499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_list[0]\n",
    "# lab_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207cec5-caaa-4934-b088-465836932f51",
   "metadata": {},
   "source": [
    "# TVT변환 진행\n",
    "\n",
    "### 1. 새 폴더 생성\n",
    "\n",
    "### 2. 이미지, 라벨링 8:1:1 비율로 분할 진행\n",
    "\n",
    "### 3. 경로 추출\n",
    "\n",
    "### 4. 파일 옮기기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70df38-cd0e-49b1-b363-cc75e23c4f4e",
   "metadata": {},
   "source": [
    "# 1.새 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f04d75-2a03-4783-9607-9605807c62f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def createFolder(save_dir):\n",
    "#     try:\n",
    "#         for tvt in ['train', 'test', 'valid']:\n",
    "#             for IL in ['images', 'annotations']:\n",
    "#                 dir = save_dir + '/' + 'coco_flexing' + '/' + tvt + '/' + IL \n",
    "#                 if not os.path.exists(dir):\n",
    "#                     os.makedirs(dir)\n",
    "#                 else:\n",
    "#                     print('Folder has already been created')\n",
    "#     except OSError:\n",
    "#         print('Error: Creating directory. ' + save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1db0ec0-0bf0-437e-8319-d8142c9b215e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#createFolder(save_dir=save_path) #바탕화면에 새 폴더 생성->해당 폴더에 TVT나누어 이미지 라벨링 파일 저장 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984af3da-7f15-4cfd-926a-a97f206c357e",
   "metadata": {},
   "source": [
    "# 2. 이미지, 라벨링 8:1:1 비율로 분할 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d80b66d-8a49-456b-92ca-dcf7bd6edaa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_tv_idx(tl, p = 0.8, m = 0.5):\n",
    "#     total_idx = range(tl)\n",
    "#     train_idx = sample(total_idx, int(tl * p)) #전체에서 80% 데이터 추출\n",
    "#     temp_idx = set(total_idx) - set(train_idx) #전체 인덱스값에서 트레인 데이터에 해당하는 인덱스 제거\n",
    "#     valid_idx = sample(temp_idx, int(len(temp_idx) * m)) #남은 인덱스값에서 50%추출->전체데이터에서 10%추출\n",
    "#     test_idx = set(temp_idx) - set(valid_idx) #전체에서 10%데이터 추출\n",
    "\n",
    "#     return train_idx, valid_idx, list(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b839b8d-cbdb-4435-bab3-3276a1c669de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_idx, valid_idx, test_idx = get_tv_idx(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4798380-b47a-4b09-bc35-e94e22e08403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(train_idx))\n",
    "# print(len(valid_idx))\n",
    "# print(len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15833f29-d991-48a0-964c-430e15bc0ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c136b34-9c4f-4001-88d4-319178529e66",
   "metadata": {},
   "source": [
    "# TVT별 이미지, 라벨링 데이터 경로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c917e254-18c4-4378-b41e-3f76bef149c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_img_list = [file_list[idx] for idx in train_idx]\n",
    "# train_lab_list= [file.replace('.jpg','.json') for file in train_img_list]\n",
    "# print(train_img_list[:5])\n",
    "# print(train_lab_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca91ec1d-6140-4157-971d-24d2041c59ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid_img_list = [file_list[idx] for idx in valid_idx]\n",
    "# valid_lab_list= [file.replace('.jpg','.json') for file in valid_img_list]\n",
    "# print(valid_img_list[:5])\n",
    "# print(valid_lab_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5af696b-5749-44b8-b8f2-374aef028657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_img_list = [file_list[idx] for idx in test_idx]\n",
    "# test_lab_list= [file.replace('.jpg','.json') for file in test_img_list]\n",
    "# print(test_img_list[:5])\n",
    "# print(test_lab_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f5020-356a-42d3-ba09-68db895fc527",
   "metadata": {},
   "source": [
    "# 파일 저장소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e30370e2-521d-449d-8df4-30a632b793ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path='C:/Users/user/Desktop/coco_flexing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801141da-f805-4143-90ec-97e7b8d1435c",
   "metadata": {},
   "source": [
    "# data 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd4ac6cc-4971-47e5-9b44-57863958334b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01_원천데이터', '02_라벨링데이터']\n",
      "C:/Users/user/Desktop/sample_flexink\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(path))\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1cb473-42e6-43e4-8ff5-b13f912a0b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Desktop/coco_flexing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4c66a0a-cdd6-4065-8c9c-878efa110bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotations', 'images']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(save_path+'/'+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6cb89ef-ce2b-4982-b539-6244294a11cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # train\n",
    "# for i in train_img_list:\n",
    "#     shutil.copy(path+'/'+'01_원천데이터'+'/'+i,save_path+'/'+'train'+'/'+'images') # image copy\n",
    "# for j in train_lab_list:\n",
    "#     shutil.copy(path+'/'+'02_라벨링데이터'+'/'+j,save_path+'/'+'train'+'/'+'annotations') #label copy \n",
    "\n",
    "# # valid\n",
    "# for i in valid_img_list:\n",
    "#     shutil.copy(path+'/'+'01_원천데이터'+'/'+i,save_path+'/'+'valid'+'/'+'images') # image copy\n",
    "# for j in valid_lab_list:\n",
    "#     shutil.copy(path+'/'+'02_라벨링데이터'+'/'+j,save_path+'/'+'valid'+'/'+'annotations') #label copy \n",
    "\n",
    "# # test\n",
    "# for i in test_img_list:\n",
    "#     shutil.copy(path+'/'+'01_원천데이터'+'/'+i,save_path+'/'+'test'+'/'+'images') # image copy\n",
    "# for j in test_lab_list:\n",
    "#     shutil.copy(path+'/'+'02_라벨링데이터'+'/'+j,save_path+'/'+'test'+'/'+'annotations') #label copy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c172803-b9ea-488f-bfaf-95c47664f0df",
   "metadata": {},
   "source": [
    "# 파일명 순서대로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9686793a-3c86-4f2f-9635-830668b87386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['halibut', 'instances_train.json', 'instances_val.json']\n"
     ]
    }
   ],
   "source": [
    "train_ann=os.listdir(save_path+'/'+'train'+'/'+'annotations')\n",
    "print(train_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30a7b86f-f46e-4c29-b419-595f9a9554eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['halibut', 'instances_val.json']\n"
     ]
    }
   ],
   "source": [
    "valid_ann=os.listdir(save_path+'/'+'valid'+'/'+'annotations')\n",
    "print(valid_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a87a6389-2095-43da-8f40-8793d108fa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['halibut', 'instances_test.json']\n"
     ]
    }
   ],
   "source": [
    "test_ann=os.listdir(save_path+'/'+'test'+'/'+'annotations')\n",
    "print(test_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edff1a-980a-46ed-a3fd-c431865eddb8",
   "metadata": {},
   "source": [
    "# 파일명 확인(순서대로 들어가야함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf585b-5a89-4b5b-bc1a-fb73f0a14a58",
   "metadata": {},
   "source": [
    "# COCO dataset 형식 작성\n",
    "\n",
    "## RetinaNet은 Train, Valid, Test 당 각각 한개의 annotations 파일이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69d0a717-abea-49d2-b494-2773cd62860a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coco_data_train = {\n",
    "    \"info\": {\n",
    "        \"year\": \"2023\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"MYUNGSUN\",\n",
    "        \"contributor\": \"\",\n",
    "        \"url\": \"MYUNGSUN\",\n",
    "        \"date_created\": \"2022-11-16 09:27:18\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"url\": \"MYUNGSUN\",\n",
    "            \"name\": \"Image of halibut\"\n",
    "        }\n",
    "    ],\n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"background\",\n",
    "            \"supercategory\": \"none\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"halibut\",\n",
    "            \"supercategory\": \"none\"\n",
    "        }\n",
    "    ],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "# 이미지 및 객체 ID 변수 초기화\n",
    "image_id = 0\n",
    "annotation_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfd412-d056-4b7b-a59d-e85868c77de8",
   "metadata": {},
   "source": [
    "# images 항목 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9ed61b-d4a7-4b59-90e5-6c5d628646bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"images\": [{\"IMAGE_URL\": \"https://images.labelon.kr/2022/07/14/7fcea8fc45e541e4b4daf6c2eeaa23e4.jpg\", \"id\": 0, \"width\": 1920, \"height\": 1080, \"file_name\": \"01_1_R_LA_NA_20220707_01_053.jpg\"}]\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images 항목 예시\n",
    "'''\n",
    "\"images\": [{\"IMAGE_URL\": \"https://images.labelon.kr/2022/07/14/7fcea8fc45e541e4b4daf6c2eeaa23e4.jpg\", \"id\": 0, \"width\": 1920, \"height\": 1080, \"file_name\": \"01_1_R_LA_NA_20220707_01_053.jpg\"}]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78f8f223-27c0-41e0-b747-8a21babdf904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Desktop/coco_flexing'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79bc25a4-4684-4a12-a33d-460ac9d6c626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label_file in train_ann: #train_ann값으로 \n",
    "    with open(save_path+'/'+'train'+'/'+'annotations'+'/'+label_file, \"r\",encoding='UTF-8') as f:\n",
    "        label_data = json.load(f)\n",
    "    \n",
    "    # coco_dataset의 images항목 채우기\n",
    "    image_info=label_data['Info']\n",
    "    image_info['id']=image_id #image_id 0부터 시작\n",
    "    coco_data_train['images'].append(image_info) #라벨링 데이터 info항목 붙여넣기\n",
    "    \n",
    "    # annotations 항목 채우기 객체 정보 추가\n",
    "    annotation_info = label_data[\"Annotations\"]\n",
    "    for annotation in annotation_info:\n",
    "        annotation[\"id\"] = annotation_id #d어노테이션 고유 ID\n",
    "        annotation[\"image_id\"] = image_id #이미지 고유 ID\n",
    "        coco_data_train[\"annotations\"].append(annotation)\n",
    "        annotation_id+=1\n",
    "    image_id += 1 #image_id +1씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b7688c5-cd80-48a1-82a1-bc1ac33f55ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "print(len(coco_data_train['images']))\n",
    "print(len(coco_data_train['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbaf51b3-d7ea-4fb5-b002-9aaa92e08002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'filename': 'SA12_T01_FR_000002.JPG',\n",
       " 'file_folder': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어',\n",
       " 'resolution': '[1536, 1024]',\n",
       " 'region_name': 'T01',\n",
       " 'date': '2022:08:22 10:30:29',\n",
       " 'file format': 'JPEG',\n",
       " 'copyright': 'MYUNGSUN',\n",
       " 'pixel': '1572864',\n",
       " 'camera device': 'digital camera'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_train['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f7fc9ba-a054-4aad-9e4c-495990f26f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#이미지 라벨링 파일 변경\n",
    "for item in coco_data_train[\"images\"]:\n",
    "    resolution=eval(item[\"resolution\"])\n",
    "    item[\"width\"]=resolution[0]\n",
    "    item[\"height\"]=resolution[1]\n",
    "    item[\"file_name\"] = item.pop('filename')\n",
    "    item[\"IMAGE_URL\"]=item[\"file_folder\"]\n",
    "    del item['resolution']\n",
    "    del item['file_folder']\n",
    "    del item['region_name']\n",
    "    del item['date']\n",
    "    del item['file format']\n",
    "    del item['copyright']\n",
    "    del item['pixel']\n",
    "    del item['camera device']\n",
    "    del item['IMAGE_URL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a4ee5-6f2a-49e5-a604-091923cbad3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# coco_data_train images 항목 작성 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fecca148-3413-438e-8c98-60624042d357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'width': 1536,\n",
       "  'height': 1024,\n",
       "  'file_name': 'SA12_T01_FR_000002.JPG'},\n",
       " {'id': 1,\n",
       "  'width': 1536,\n",
       "  'height': 1024,\n",
       "  'file_name': 'SA12_T01_FR_000004.JPG'},\n",
       " {'id': 2,\n",
       "  'width': 1536,\n",
       "  'height': 1024,\n",
       "  'file_name': 'SA12_T01_FR_000007.JPG'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_train['images'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b8f31-d479-4684-afeb-071892afa9d3",
   "metadata": {},
   "source": [
    "# annotations 항목 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34f91938-7d7e-4754-bdc1-c4ecbb4d4f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0}, \\nid=annotations의 id->각각의 어노테이션의 ID\\nimage_id=이미지 id->이미지 한장당 ID\\ncategory_id=class_id->class 고유 ID\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# annotations 예시\n",
    "'''\n",
    "\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0}, \n",
    "id=annotations의 id->각각의 어노테이션의 ID\n",
    "image_id=이미지 id->이미지 한장당 ID\n",
    "category_id=class_id->class 고유 ID\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be9a9716-338b-4e23-b0e3-c4d61c487d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70326ca6-d24b-4cb3-94ca-1d7655361b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_id': 3,\n",
       " 'annotation_type': 'polygon',\n",
       " 'class_code': 'halibut',\n",
       " 'class_name': '넙치치어',\n",
       " 'rect.points': None,\n",
       " 'polygon.points': '[1246,1251,1255,1259,1269,1275,1282,1285,1289,1302,1322,1326,1341,1343,1344,1346,1347,1347,1346,1342,1339,1337,1328,1313,1304,1293,1282,1269,1247,1224,1210,1226,1239],[212,201,195,194,188,180,170,169,167,160,156,156,155,156,158,170,175,181,187,199,201,206,223,244,256,267,277,285,298,309,297,257,229]',\n",
       " 'morphic_step': None,\n",
       " 'spawn': None,\n",
       " 'memo': None,\n",
       " 'id': 230,\n",
       " 'image_id': 76}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_train['annotations'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03ff6112-d591-48a0-ba46-2ae1bd892b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for annotation in coco_data_train['annotations']:\n",
    "    if annotation['class_code'] == 'halibut':\n",
    "        annotation['category_id'] = 1\n",
    "    else:\n",
    "        pass\n",
    "    annotation['segmentation']=[]\n",
    "    annotation['iscrowd']=0\n",
    "    # bbox 계산\n",
    "    points=annotation['polygon.points'].split(\"],[\")\n",
    "    x_points=ast.literal_eval(points[0].replace(\"[\",\"\")) #x좌표 추출\n",
    "    y_points=ast.literal_eval(points[1].replace(\"]\",\"\")) #y좌표 추출\n",
    "    xmin,xmax=min(x_points),max(x_points) #x 최소값, x최대값\n",
    "    ymin,ymax=min(y_points),max(y_points) #y 최소값, y최대값\n",
    "    width=xmax-xmin #넓이->x최대값-x최소값\n",
    "    height=ymax-ymin #높이->y최대값-y최소값\n",
    "    \n",
    "    annotation['bbox']=[xmin,ymin,width,height]\n",
    "    annotation['area']=width*height\n",
    "    \n",
    "    ### 좌표값 반환\n",
    "    del annotation['morphic_step']\n",
    "    del annotation['spawn']\n",
    "    del annotation['memo']\n",
    "    del annotation['rect.points']\n",
    "    del annotation['class_name']\n",
    "    del annotation['class_code']\n",
    "    del annotation['annotation_id']\n",
    "    del annotation['annotation_type']\n",
    "    del annotation['polygon.points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb3ff428-5dab-4cc4-b9d8-d4d3fed0e592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 239,\n",
       " 'image_id': 79,\n",
       " 'category_id': 1,\n",
       " 'segmentation': [],\n",
       " 'iscrowd': 0,\n",
       " 'bbox': [1128, 268, 98, 162],\n",
       " 'area': 15876}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_train['annotations'][239]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb80b56-9af5-4e87-a8e2-be4d6c6ee285",
   "metadata": {},
   "source": [
    "# Train 라벨링 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b46ed584-4957-4b55-ae6e-cfd462a2674f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = \"instances_train.json\"\n",
    "with open(save_path+'/'+'train'+'/'+'annotations'+'/'+output_file, \"w\") as f:\n",
    "    json.dump(coco_data_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fbccd8a-bebe-460f-956b-147cb6bfa28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 구축한 coco dataset 확인\n",
    "# for i in coco_data_train['images']:\n",
    "#     name=i['file_name']\n",
    "#     if os.path.exists(save_path+'/'+'train'+'/'+'images'+'/'+name):\n",
    "#         print('있음')\n",
    "#     else:\n",
    "#         print('없음')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e58fa-0a2c-48ff-af09-e41b2568cf60",
   "metadata": {},
   "source": [
    "# Vaild COCO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce52750-f8ad-4085-8c6c-dd10d04cf859",
   "metadata": {},
   "source": [
    "# Valid data build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fab5635-071c-44cd-b8e5-2b7ba745de0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coco_data_val = {\n",
    "    \"info\": {\n",
    "        \"year\": \"2023\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"MYUNGSUN\",\n",
    "        \"contributor\": \"\",\n",
    "        \"url\": \"MYUNGSUN\",\n",
    "        \"date_created\": \"2022-11-16 09:27:18\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"url\": \"MYUNGSUN\",\n",
    "            \"name\": \"Image of halibut\"\n",
    "        }\n",
    "    ],\n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"background\",\n",
    "            \"supercategory\": \"none\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"halibut\",\n",
    "            \"supercategory\": \"none\"\n",
    "        }\n",
    "    ],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "# 이미지 및 객체 ID 변수 초기화\n",
    "image_id = 0\n",
    "annotation_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efd50cae-53c3-4f00-acd2-5b0ef907c03c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA12_T01_FR_000096.json',\n",
       " 'SA12_T01_FR_000097.json',\n",
       " 'SA12_T01_FR_000098.json',\n",
       " 'SA12_T01_FR_000099.json',\n",
       " 'SA12_T01_FR_000100.json',\n",
       " 'SA12_T01_FR_000101.json',\n",
       " 'SA12_T01_FR_000102.json',\n",
       " 'SA12_T01_FR_000103.json',\n",
       " 'SA12_T01_FR_000104.json',\n",
       " 'SA12_T01_FR_000105.json']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2fd6df2b-be6d-493c-816c-2f9de100e647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label_file in valid_ann:\n",
    "    with open(save_path+'/'+'valid'+'/'+'annotations'+'/'+label_file, \"r\",encoding='UTF-8') as f:\n",
    "        label_data = json.load(f)\n",
    "        \n",
    "        \n",
    "    # coco_dataset의 images항목 채우기\n",
    "    image_info=label_data['Info']\n",
    "    image_info['id']=image_id #image_id 0부터 시작\n",
    "    coco_data_val['images'].append(image_info) #라벨링 데이터 info항목 붙여넣기\n",
    "    \n",
    "    # annotations 항목 채우기 객체 정보 추가\n",
    "    annotation_info = label_data[\"Annotations\"]\n",
    "    for annotation in annotation_info:\n",
    "        annotation[\"id\"] = annotation_id\n",
    "        annotation[\"image_id\"] = image_id\n",
    "        coco_data_val[\"annotations\"].append(annotation)\n",
    "        annotation_id+=1\n",
    "    image_id += 1 #image_id +1씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f20cfb3-3a62-4bf8-a0fd-93c2c1df77a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(coco_data_val['images']))\n",
    "print(len(coco_data_val['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba819199-af8a-4743-acbf-c70ff39b0505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'filename': 'SA12_T01_FR_000096.JPG',\n",
       " 'file_folder': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어',\n",
       " 'resolution': '[1536, 1024]',\n",
       " 'region_name': 'T01',\n",
       " 'date': '2022:08:22 11:55:48',\n",
       " 'file format': 'JPEG',\n",
       " 'copyright': 'MYUNGSUN',\n",
       " 'pixel': '1572864',\n",
       " 'camera device': 'digital camera'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_val['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f26a8ca-0a83-49e6-a5e8-4ebb81da5c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#이미지 라벨링 파일 변경\n",
    "for item in coco_data_val['images']:\n",
    "    resolution=eval(item['resolution'])\n",
    "    item['width']=resolution[0]\n",
    "    item['height']=resolution[1]\n",
    "    item['file_name'] = item.pop('filename')\n",
    "    item['IMAGE_URL']=item['file_folder']\n",
    "    del item['resolution']\n",
    "    del item['file_folder']\n",
    "    del item['region_name']\n",
    "    del item['date']\n",
    "    del item['file format']\n",
    "    del item['copyright']\n",
    "    del item['pixel']\n",
    "    del item['camera device']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f385562-a652-45af-b264-b40aca4d47dd",
   "metadata": {},
   "source": [
    "# images 항목 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa43f4cb-b5f3-4365-895a-c06bc75b5428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"images\": [{\"IMAGE_URL\": \"https://images.labelon.kr/2022/07/14/7fcea8fc45e541e4b4daf6c2eeaa23e4.jpg\", \"id\": 0, \"width\": 1920, \"height\": 1080, \"file_name\": \"01_1_R_LA_NA_20220707_01_053.jpg\"}]\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images 항목 예시\n",
    "'''\n",
    "\"images\": [{\"IMAGE_URL\": \"https://images.labelon.kr/2022/07/14/7fcea8fc45e541e4b4daf6c2eeaa23e4.jpg\", \"id\": 0, \"width\": 1920, \"height\": 1080, \"file_name\": \"01_1_R_LA_NA_20220707_01_053.jpg\"}]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b72487e5-6a91-4e86-8fa5-9ddcfd06082a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'width': 1536,\n",
       " 'height': 1024,\n",
       " 'file_name': 'SA12_T01_FR_000096.JPG',\n",
       " 'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_val['images'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03cee8-c756-46f6-9bb7-570ae79a464a",
   "metadata": {},
   "source": [
    "# annotations 항목 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3f98aaf-fe3f-46c9-8206-fda119be895b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0},\\n\\n\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0}, \\nid=annotations의 id\\nimage_id=이미지 id\\ncategory_id=class_id\\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# annotations 예시\n",
    "'''\n",
    "\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0},\n",
    "\n",
    "\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0}, \n",
    "id=annotations의 id\n",
    "image_id=이미지 id\n",
    "category_id=class_id\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9874fedd-c8c2-4c0a-bb8a-704f33437cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_id': 1,\n",
       " 'annotation_type': 'polygon',\n",
       " 'class_code': 'halibut',\n",
       " 'class_name': '넙치치어',\n",
       " 'rect.points': None,\n",
       " 'polygon.points': '[687,676,654,633,619,611,612,612,614,615,611,608,608,610,615,616,619,622,624,644,653,658,662,666,667,666,674,691,697,704,706,704],[948,942,913,885,870,858,850,844,840,836,833,824,817,810,805,789,774,764,762,767,772,776,776,783,786,789,797,836,859,904,933,942]',\n",
       " 'morphic_step': None,\n",
       " 'spawn': None,\n",
       " 'memo': None,\n",
       " 'id': 0,\n",
       " 'image_id': 0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_val['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "160e53bf-51f6-4b48-8a7d-404b71f70f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for annotation in coco_data_val['annotations']:\n",
    "    if annotation['class_code'] == 'halibut':\n",
    "        annotation['category_id'] = 1\n",
    "    else:\n",
    "        pass\n",
    "    annotation['segmentation']=[]\n",
    "    annotation['iscrowd']=0\n",
    "    # bbox 계산\n",
    "    points=annotation['polygon.points'].split(\"],[\")\n",
    "    x_points=ast.literal_eval(points[0].replace(\"[\",\"\")) #x좌표 추출\n",
    "    y_points=ast.literal_eval(points[1].replace(\"]\",\"\")) #y좌표 추출\n",
    "    xmin,xmax=min(x_points),max(x_points) #x 최소값, x최대값\n",
    "    ymin,ymax=min(y_points),max(y_points) #y 최소값, y최대값\n",
    "    width=xmax-xmin #넓이->x최대값-x최소값\n",
    "    height=ymax-ymin #높이->y최대값-y최소값\n",
    "    \n",
    "    annotation['bbox']=[xmin,ymin,width,height]\n",
    "    annotation['area']=width*height\n",
    "    \n",
    "    ### 좌표값 반환\n",
    "    del annotation['morphic_step']\n",
    "    del annotation['spawn']\n",
    "    del annotation['memo']\n",
    "    del annotation['rect.points']\n",
    "    del annotation['class_name']\n",
    "    del annotation['class_code']\n",
    "    del annotation['annotation_id']\n",
    "    del annotation['annotation_type']\n",
    "    del annotation['polygon.points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f67e2d52-ab77-4bbb-af61-45383bfd8916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = \"instances_val.json\"\n",
    "with open(save_path+'/'+'valid'+'/'+'annotations'+'/'+output_file, \"w\") as f:\n",
    "    json.dump(coco_data_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "edbd1829-c51b-48ef-aff6-ecd55449e327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'year': '2023',\n",
       "  'version': '1.0',\n",
       "  'description': 'MYUNGSUN',\n",
       "  'contributor': '',\n",
       "  'url': 'MYUNGSUN',\n",
       "  'date_created': '2022-11-16 09:27:18'},\n",
       " 'licenses': [{'id': 1, 'url': 'MYUNGSUN', 'name': 'Image of halibut'}],\n",
       " 'categories': [{'id': 0, 'name': 'background', 'supercategory': 'none'},\n",
       "  {'id': 1, 'name': 'halibut', 'supercategory': 'none'}],\n",
       " 'images': [{'id': 0,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000096.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 1,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000097.JPG',\n",
       "   'IMAGE_URL': '01.데이터/2.Validation/원천데이터/11.넙치치어,01.데이터/2.Validation/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 2,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000098.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 3,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000099.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 4,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000100.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 5,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000101.JPG',\n",
       "   'IMAGE_URL': '01.데이터/2.Validation/원천데이터/11.넙치치어,01.데이터/2.Validation/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 6,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000102.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 7,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000103.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 8,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000104.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'},\n",
       "  {'id': 9,\n",
       "   'width': 1536,\n",
       "   'height': 1024,\n",
       "   'file_name': 'SA12_T01_FR_000105.JPG',\n",
       "   'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'}],\n",
       " 'annotations': [{'id': 0,\n",
       "   'image_id': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [608, 762, 98, 186],\n",
       "   'area': 18228},\n",
       "  {'id': 1,\n",
       "   'image_id': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1149, 605, 122, 188],\n",
       "   'area': 22936},\n",
       "  {'id': 2,\n",
       "   'image_id': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1101, 283, 108, 152],\n",
       "   'area': 16416},\n",
       "  {'id': 3,\n",
       "   'image_id': 1,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [137, 247, 179, 69],\n",
       "   'area': 12351},\n",
       "  {'id': 4,\n",
       "   'image_id': 1,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [655, 185, 207, 212],\n",
       "   'area': 43884},\n",
       "  {'id': 5,\n",
       "   'image_id': 1,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1137, 605, 136, 213],\n",
       "   'area': 28968},\n",
       "  {'id': 6,\n",
       "   'image_id': 2,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [240, 309, 198, 99],\n",
       "   'area': 19602},\n",
       "  {'id': 7,\n",
       "   'image_id': 2,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [719, 245, 171, 129],\n",
       "   'area': 22059},\n",
       "  {'id': 8,\n",
       "   'image_id': 2,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1128, 706, 151, 124],\n",
       "   'area': 18724},\n",
       "  {'id': 9,\n",
       "   'image_id': 3,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [212, 271, 138, 107],\n",
       "   'area': 14766},\n",
       "  {'id': 10,\n",
       "   'image_id': 3,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [659, 267, 171, 123],\n",
       "   'area': 21033},\n",
       "  {'id': 11,\n",
       "   'image_id': 3,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1192, 779, 126, 157],\n",
       "   'area': 19782},\n",
       "  {'id': 12,\n",
       "   'image_id': 4,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [657, 600, 145, 131],\n",
       "   'area': 18995},\n",
       "  {'id': 13,\n",
       "   'image_id': 4,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [155, 190, 118, 147],\n",
       "   'area': 17346},\n",
       "  {'id': 14,\n",
       "   'image_id': 4,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1097, 187, 143, 125],\n",
       "   'area': 17875},\n",
       "  {'id': 15,\n",
       "   'image_id': 5,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [318, 239, 107, 152],\n",
       "   'area': 16264},\n",
       "  {'id': 16,\n",
       "   'image_id': 5,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [766, 184, 133, 164],\n",
       "   'area': 21812},\n",
       "  {'id': 17,\n",
       "   'image_id': 5,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1125, 686, 218, 79],\n",
       "   'area': 17222},\n",
       "  {'id': 18,\n",
       "   'image_id': 6,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [619, 182, 149, 155],\n",
       "   'area': 23095},\n",
       "  {'id': 19,\n",
       "   'image_id': 6,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1103, 349, 171, 82],\n",
       "   'area': 14022},\n",
       "  {'id': 20,\n",
       "   'image_id': 6,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1156, 682, 147, 104],\n",
       "   'area': 15288},\n",
       "  {'id': 21,\n",
       "   'image_id': 7,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [214, 208, 69, 167],\n",
       "   'area': 11523},\n",
       "  {'id': 22,\n",
       "   'image_id': 7,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [652, 609, 193, 82],\n",
       "   'area': 15826},\n",
       "  {'id': 23,\n",
       "   'image_id': 7,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1295, 320, 85, 166],\n",
       "   'area': 14110},\n",
       "  {'id': 24,\n",
       "   'image_id': 8,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [275, 129, 146, 174],\n",
       "   'area': 25404},\n",
       "  {'id': 25,\n",
       "   'image_id': 8,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [763, 196, 87, 225],\n",
       "   'area': 19575},\n",
       "  {'id': 26,\n",
       "   'image_id': 8,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1149, 224, 141, 176],\n",
       "   'area': 24816},\n",
       "  {'id': 27,\n",
       "   'image_id': 9,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [1163, 102, 100, 161],\n",
       "   'area': 16100},\n",
       "  {'id': 28,\n",
       "   'image_id': 9,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [621, 573, 85, 183],\n",
       "   'area': 15555},\n",
       "  {'id': 29,\n",
       "   'image_id': 9,\n",
       "   'category_id': 1,\n",
       "   'segmentation': [],\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [728, 310, 175, 68],\n",
       "   'area': 11900}]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a090a15-5df1-4ab6-a49d-3c1b0cb750ab",
   "metadata": {},
   "source": [
    "# Test COCO build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ece57-e3c9-47d3-9b9b-7cba187c4dce",
   "metadata": {},
   "source": [
    "# Test Data Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5333ec34-14f8-4ce0-a1a0-73b829fdc438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coco_data_test = {\n",
    "    \"info\": {\n",
    "        \"year\": \"2023\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"MYUNGSUN\",\n",
    "        \"contributor\": \"\",\n",
    "        \"url\": \"MYUNGSUN\",\n",
    "        \"date_created\": \"2022-11-16 09:27:18\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"url\": \"MYUNGSUN\",\n",
    "            \"name\": \"Image of halibut\"\n",
    "        }\n",
    "    ],\n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"background\",\n",
    "            \"supercategory\": \"none\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"halibut\",\n",
    "            \"supercategory\": \"none\"\n",
    "        }\n",
    "    ],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "# 이미지 및 객체 ID 변수 초기화\n",
    "image_id = 0\n",
    "annotation_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "607451a5-f26d-48d2-bb67-19b512fa4c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test data 항목 채우기\n",
    "for label_file in test_ann:\n",
    "    with open(save_path+'/'+'test'+'/'+'annotations'+'/'+label_file, \"r\",encoding='UTF-8') as f:\n",
    "        label_data = json.load(f)\n",
    "        \n",
    "        \n",
    "    # coco_dataset의 images항목 채우기\n",
    "    image_info=label_data['Info']\n",
    "    image_info['id']=image_id #image_id 0부터 시작\n",
    "    coco_data_test['images'].append(image_info) #라벨링 데이터 info항목 붙여넣기\n",
    "    \n",
    "    # annotations 항목 채우기 객체 정보 추가\n",
    "    annotation_info = label_data[\"Annotations\"]\n",
    "    for annotation in annotation_info:\n",
    "        annotation[\"id\"] = annotation_id\n",
    "        annotation[\"image_id\"] = image_id\n",
    "        coco_data_test[\"annotations\"].append(annotation)\n",
    "        annotation_id+=1\n",
    "    image_id += 1 #image_id +1씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a079eba4-d216-40c0-8f3a-87d423ab6832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'filename': 'SA12_T01_FR_000106.JPG',\n",
       " 'file_folder': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어',\n",
       " 'resolution': '[1536, 1024]',\n",
       " 'region_name': 'T01',\n",
       " 'date': '2022:08:22 11:59:38',\n",
       " 'file format': 'JPEG',\n",
       " 'copyright': 'MYUNGSUN',\n",
       " 'pixel': '1572864',\n",
       " 'camera device': 'digital camera'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_test['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74e42dac-9ff2-40da-9577-08b05af6fa9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#이미지 라벨링 파일 변경\n",
    "for item in coco_data_test['images']:\n",
    "    resolution=eval(item['resolution'])\n",
    "    item['width']=resolution[0]\n",
    "    item['height']=resolution[1]\n",
    "    item['file_name'] = item.pop('filename')\n",
    "    item['IMAGE_URL']=item['file_folder']\n",
    "    del item['resolution']\n",
    "    del item['file_folder']\n",
    "    del item['region_name']\n",
    "    del item['date']\n",
    "    del item['file format']\n",
    "    del item['copyright']\n",
    "    del item['pixel']\n",
    "    del item['camera device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45f9f209-4a8a-49e8-8a5a-b2be10a74c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'width': 1536,\n",
       " 'height': 1024,\n",
       " 'file_name': 'SA12_T01_FR_000106.JPG',\n",
       " 'IMAGE_URL': '01.데이터/1.Training/원천데이터/11.넙치치어,01.데이터/1.Training/라벨링데이터/11.넙치치어'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_test['images'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ab9e6-d500-4343-9514-9dee4c77aebf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# annotations 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c971d7d-8933-43d3-8692-3b52c72a681d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0},\\n\\n\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0}, \\nid=annotations의 id\\nimage_id=이미지 id\\ncategory_id=class_id\\n\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# annotations 예시\n",
    "'''\n",
    "\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0},\n",
    "\n",
    "\"annotations\": [{\"id\": 0, \"image_id\": 0, \"category_id\": 1, \"bbox\": [155, 723, 60, 60], \"area\": 3600, \"segmentation\": [], \"iscrowd\": 0}, \n",
    "id=annotations의 id\n",
    "image_id=이미지 id\n",
    "category_id=class_id\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79d4b3db-316a-443e-b451-007717e9b767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_id': 1,\n",
       " 'annotation_type': 'polygon',\n",
       " 'class_code': 'halibut',\n",
       " 'class_name': '넙치치어',\n",
       " 'rect.points': None,\n",
       " 'polygon.points': '[211,227,236,247,256,271,284,297,305,315,318,321,323,326,329,331,333,335,335,334,339,341,342,343,339,334,327,319,311,301,292,281,273,271,266,260,254,244,235,228,220,210,203,198,193,187,203],[708,700,695,690,685,676,666,657,650,643,638,633,633,632,632,631,629,627,625,622,617,612,605,588,586,586,586,586,586,589,589,590,595,599,601,603,603,608,616,626,637,654,665,673,687,698,712]',\n",
       " 'morphic_step': None,\n",
       " 'spawn': None,\n",
       " 'memo': None,\n",
       " 'id': 0,\n",
       " 'image_id': 0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_test['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5dc3dc4-50f0-4b6c-9eef-d9a08c6a30ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for annotation in coco_data_test['annotations']:\n",
    "    if annotation['class_code'] == 'halibut':\n",
    "        annotation['category_id'] = 1\n",
    "    else:\n",
    "        pass\n",
    "    annotation['segmentation']=[]\n",
    "    annotation['iscrowd']=0\n",
    "    # bbox 계산\n",
    "    points=annotation['polygon.points'].split(\"],[\")\n",
    "    x_points=ast.literal_eval(points[0].replace(\"[\",\"\")) #x좌표 추출\n",
    "    y_points=ast.literal_eval(points[1].replace(\"]\",\"\")) #y좌표 추출\n",
    "    xmin,xmax=min(x_points),max(x_points) #x 최소값, x최대값\n",
    "    ymin,ymax=min(y_points),max(y_points) #y 최소값, y최대값\n",
    "    width=xmax-xmin #넓이->x최대값-x최소값\n",
    "    height=ymax-ymin #높이->y최대값-y최소값\n",
    "    \n",
    "    annotation['bbox']=[xmin,ymin,width,height]\n",
    "    annotation['area']=width*height\n",
    "    \n",
    "    ### 좌표값 반환\n",
    "    del annotation['morphic_step']\n",
    "    del annotation['spawn']\n",
    "    del annotation['memo']\n",
    "    del annotation['rect.points']\n",
    "    del annotation['class_name']\n",
    "    del annotation['class_code']\n",
    "    del annotation['annotation_id']\n",
    "    del annotation['annotation_type']\n",
    "    del annotation['polygon.points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dee76c9d-5f68-4591-a4d3-1a5755f1aec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'image_id': 0,\n",
       " 'category_id': 1,\n",
       " 'segmentation': [],\n",
       " 'iscrowd': 0,\n",
       " 'bbox': [187, 586, 156, 126],\n",
       " 'area': 19656}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data_test['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "baffa297-e027-4c20-918d-c9cb705bd050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = \"instances_test.json\"\n",
    "with open(save_path+'/'+'test'+'/'+'annotations'+'/'+output_file, \"w\") as f:\n",
    "    json.dump(coco_data_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbd797-34be-4e94-8a56-dce20600c28b",
   "metadata": {},
   "source": [
    "# 어노테이션 filne_name 항목 JPG->jpg로 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7214923-bcaf-46ae-9216-016e5dcf7658",
   "metadata": {},
   "source": [
    "# Train 파일명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fee286b8-6017-4ee5-96c0-3ca2cad0901d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for item in coco_data_train['images']:\n",
    "#     item['file_name']=item['file_name'].replace('JPG','jpg')\n",
    "\n",
    "# output_file = \"instances_train.json\"\n",
    "# with open(save_path+'/'+'train'+'/'+'annotations'+'/'+output_file, \"w\") as f:\n",
    "#     json.dump(coco_data_train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd63ca8-bc51-4dd4-b97b-432e5c56365f",
   "metadata": {},
   "source": [
    "# Valid 파일명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e8e939e-0dc0-41f8-9cfc-03ba5620e68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for item in coco_data_val['images']:\n",
    "#     item['file_name']=item['file_name'].replace('JPG','jpg')\n",
    "    \n",
    "# output_file = \"instances_val.json\"\n",
    "# with open(save_path+'/'+'valid'+'/'+'annotations'+'/'+output_file, \"w\") as f:\n",
    "#     json.dump(coco_data_val, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2167d-1657-4d83-b08c-10be24c1f9d7",
   "metadata": {},
   "source": [
    "# Test 파일명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97d8b575-6d54-493f-af39-ed257b6eca64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for item in coco_data_test['images']:\n",
    "#     item['file_name']=item['file_name'].replace('JPG','jpg')\n",
    "    \n",
    "# output_file = \"instances_test.json\"\n",
    "# with open(save_path+'/'+'test'+'/'+'annotations'+'/'+output_file, \"w\") as f:\n",
    "#     json.dump(coco_data_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f1b1b-bde5-463a-bd25-869d1e8927d1",
   "metadata": {},
   "source": [
    "# Model 구축 및 데이터 LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6de9fce0-7a54-4003-90e6-9a2be7ba3c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from anchors.ipynb\n",
      "importing Jupyter notebook from losses.ipynb\n",
      "importing Jupyter notebook from dataloader.ipynb\n",
      "importing Jupyter notebook from coco_eval.ipynb\n",
      "3.7.15 (default, Nov 24 2022, 18:44:54) [MSC v.1916 64 bit (AMD64)]\n",
      "11.6\n",
      "1.13.1+cu116\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from model import  PyramidFeatures,RegressionModel,ClassificationModel,ResNet, model_resnet18,  model_resnet34,  model_resnet50,  model_resnet101,  model_resnet152\n",
    "from dataloader import CocoDataset, Coco_testdata, collater_test,collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from coco_eval import evaluate_coco #coco eval의 코드실행\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20f591df-5b65-4d41-aea5-b158a67e26e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print('CUDA available: {}'.format(torch.cuda.is_available())) #CUDA available\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)# cuda 사용가능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08ed4990-451d-4ada-aab5-ca60c649aee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count() #사용 가능 GPU 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c27856dc-79b6-4eb0-9b2b-b19c482ccefd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/Desktop/coco_flexing'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 저장 장소\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66a7b6a5-f55f-4873-8636-6882d4147d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotations', 'images']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(save_path+'/'+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22ccfc9d-5f71-470a-b653-87cac56b591b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train=CocoDataset(data_dir=save_path+'/'+'train',set_name='train',transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cfd9730-def1-4ca2-a7ba-cfc4c69488ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'background': 0, 'halibut': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.class_list_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6969851-7ded-446b-91f6-1c3fa8826acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.num_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dabd20bd-a7bb-455c-894b-4e47c1af186c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[0.2036, 0.3376, 0.5583],\n",
       "          [0.2060, 0.3401, 0.5608],\n",
       "          [0.1996, 0.3336, 0.5543],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.2137, 0.3479, 0.5686],\n",
       "          [0.2157, 0.3500, 0.5706],\n",
       "          [0.2054, 0.3395, 0.5602],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.2131, 0.3472, 0.5683],\n",
       "          [0.2027, 0.3365, 0.5574],\n",
       "          [0.2151, 0.3493, 0.5699],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]]),\n",
       " 'annot': tensor([[449.1667, 137.5000, 525.0000, 174.5833,   1.0000],\n",
       "         [297.5000,  82.0833, 389.1667, 127.0833,   1.0000],\n",
       "         [ 66.2500, 111.6667, 144.1667, 143.7500,   1.0000]],\n",
       "        dtype=torch.float64),\n",
       " 'scale': 0.4166666666666667}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3faf53c-6b75-4657-979d-d915fee13bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Retina(path,depth,epochs):\n",
    "    print(f'resnet_{depth} backbone 사용하고, {epochs}번 반복하여 학습합니다')\n",
    "    #train coco dataset\n",
    "    dataset_train=CocoDataset(data_dir=path+'/'+'train',set_name='train',transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "    dataset_val=CocoDataset(data_dir=path+'/'+'valid',set_name='val',transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "    print('train coco build, valid coco bild')    \n",
    "        \n",
    "    #sampler->batch size로 데이터를 나눠주는듯 함\n",
    "    sampler=AspectRatioBasedSampler(dataset_train, batch_size=4, drop_last=False)\n",
    "    dataloader_train = DataLoader(dataset_train, num_workers=0, collate_fn=collater, batch_sampler=sampler) #num_workers=3이 default\n",
    "    \n",
    "    #dataloader_train=DataLoader(dataset_train,num_workers=1,collate_fn=collater,batch_size=2)\n",
    "    if dataset_val is not None:\n",
    "        sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=4, drop_last=False) #ex) [756,777]\n",
    "        dataloader_val = DataLoader(dataset_val, num_workers=0, collate_fn=collater, batch_sampler=sampler_val)\n",
    "    print('dataloader build success')\n",
    "    print('총 클래스 개수',dataset_train.num_classes())\n",
    "    print('총 데이터',len(dataset_train))\n",
    "    print('dataloader iteration',len(dataloader_train))\n",
    "    # Create the model depth에 따라 모델 선택 달라짐\n",
    "    if depth == 18:\n",
    "        retinanet = model_resnet18(num_classes=dataset_train.num_classes(), pretrained=False)\n",
    "    elif depth == 34:\n",
    "        retinanet = model_resnet34(num_classes=dataset_train.num_classes(), pretrained=False)\n",
    "    elif depth == 50:\n",
    "        retinanet = model_resnet50(num_classes=dataset_train.num_classes(), pretrained=True) #현재 오류 발생 지점\n",
    "    elif depth == 101:\n",
    "        retinanet = model_resnet101(num_classes=dataset_train.num_classes(), pretrained=False)\n",
    "    elif depth == 152:\n",
    "        retinanet = model_resnet152(num_classes=dataset_train.num_classes(), pretrained=False)\n",
    "    else:\n",
    "        raise ValueError('Unsupported model depth, must be one of 18, 34, 50, 101, 152')\n",
    "        \n",
    "    #모델 파라미터 사이즈 확인 코드\n",
    "    # for name, param in retinanet.named_parameters():\n",
    "    #     print(name, param.size())\n",
    "        \n",
    "    use_gpu = True #GPU 사용여부 True\n",
    "    GPU_num=torch.cuda.device_count()\n",
    "    #print(use_gpu)\n",
    "    \n",
    "    #GPU한개일때\n",
    "#    if use_gpu:\n",
    "#        print('GPU사용')\n",
    "#        if torch.cuda.is_available():\n",
    "#            print('CUDA사용')\n",
    "#            if GPU_num==1:\n",
    "#                print('사용 GPU 1개')\n",
    "#                #retinanet = retinanet.cuda()\n",
    "#                retinanet=retinanet.to(device) #cuda로 이동\n",
    "    retinanet=retinanet.to(device)\n",
    "                \n",
    "    #GPU 한개 이상\n",
    "#     if use_gpu:\n",
    "#         if torch.cuda.is_available():\n",
    "#             if GPU_num > 1:\n",
    "#                 print(\"GPU 1개 이상 사용\")\n",
    "#                 retinanet = torch.nn.DataParallel(retinanet).to(device)\n",
    "                \n",
    "#     else:\n",
    "#         print('CPU 사용')\n",
    "#         retinanet=torch.nn.DataParallel(retinanet).to(device)\n",
    "                \n",
    "                \n",
    "\n",
    "#     if use_gpu:\n",
    "#         if torch.cuda.is_available(): #cuda 사용여부\n",
    "#             retinanet = retinanet.cuda() #cuda memory에 RetinaNet load\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         print('CUDA사용')\n",
    "#         retinanet = torch.nn.DataParallel(retinanet).cuda() #병렬처리->코드 알아보기\n",
    "#     else:\n",
    "#         print('CPU사용')\n",
    "#         retinanet = torch.nn.DataParallel(retinanet)\n",
    "\n",
    "    retinanet.training = True #train여부\n",
    "\n",
    "    optimizer = optim.Adam(retinanet.parameters(), lr=1e-5) #Adam optimizer사용\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',patience=3, verbose=True) #scheduler 설정\n",
    "\n",
    "    loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "    retinanet.train() #train Mode\n",
    "    if GPU_num==1:\n",
    "        retinanet.freeze_bn() #batchnormalization 고정\n",
    "    else:\n",
    "        # retinanet.module.freeze_bn() #병렬처리할때 ON\n",
    "        pass\n",
    "\n",
    "    print('Num training images: {}'.format(len(dataset_train))) #Num training images 57~~~\n",
    "\n",
    "    for epoch_num in range(epochs):#학습 시작\n",
    "        print(\"Train start\")\n",
    "        print(f'epoch {epoch_num+1} start')\n",
    "\n",
    "        retinanet.train() #train Mode\n",
    "        if GPU_num==1:\n",
    "            retinanet.freeze_bn()\n",
    "        else:\n",
    "            # retinanet.module.freeze_bn()\n",
    "            pass\n",
    "\n",
    "        epoch_loss = [] #loss append list\n",
    "        print('Model학습 시작')\n",
    "        for iter_num, data in enumerate(dataloader_train): #index, data->image=2,3,608,640 for문 제대로안돌아감\n",
    "            optimizer.zero_grad() #gradient 초기화\n",
    "            #print('Model학습 시작')\n",
    "            classification_loss, regression_loss = retinanet([data['img'].to(device).float(), data['annot'].to(device)]) #classification, regression loss,여기서부터 오류발생\n",
    "            classification_loss = classification_loss.mean() #classification loss mean\n",
    "            regression_loss = regression_loss.mean() #regression loss mean\n",
    "\n",
    "            loss = classification_loss + regression_loss #두 loss sum\n",
    "\n",
    "            loss.backward() #back propagation\n",
    "            torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1) #gradient전체 norm이 0.1을 넘지 않도록 방지\n",
    "            optimizer.step() #가중치 업로드\n",
    "            loss_hist.append(float(loss)) #loss append\n",
    "            epoch_loss.append(float(loss)) #epoch당 loss\n",
    "\n",
    "            #epoch 마다 loss값을 츨력해줌\n",
    "            # if iter_num%50==0:\n",
    "            #     print('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(epoch_num+1, iter_num+1, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
    "\n",
    "            del classification_loss #print 끝나면 classification_loss삭제\n",
    "            del regression_loss #print 끝나면 regression loss삭제함.\n",
    "        print(f'{epoch_num+1} 학습 완료')\n",
    "        train_yes=epoch_num+1\n",
    "        if train_yes==epoch_num+1:\n",
    "            #evaluate validation dataset\n",
    "            print(\"Start Evaluating val datset\")\n",
    "            #evaluate_coco(dataset_val,retinanet)\n",
    "            class_AP=evaluate_coco(dataset_val,retinanet,path=path) #map, ap 저장\n",
    "            #전체 결과 출력 한 epoch당임\n",
    "            # 전체 클래스 mAP50\n",
    "            print('-'*40)\n",
    "            print(f'전체 클래스 mAP:50={round(class_AP.stats[1]*100,2)}%')\n",
    "            print('-'*40)\n",
    "            print(f'Large 객체에 대한 mAP:50:0.95={round(class_AP.stats[5]*100,2)}%')\n",
    "            print('-'*40)\n",
    "            print(f'Medium 객체에 대한 mAP:50:0.95={round(class_AP.stats[4]*100,2)}%')\n",
    "            print('-'*40)\n",
    "            print(f'Small 객체에 대한 mAP:50:0.95={round(class_AP.stats[3]*100,2)}%')\n",
    "            print('-'*40)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        scheduler.step(np.mean(epoch_loss))\n",
    "    print('Train, Evaluation 완료, 결과값 저장 중')\n",
    "    if GPU_num>1:\n",
    "        torch.save(retinanet.module, './models/retina_final.pt')\n",
    "        torch.save(retinanet.module.state_dict(), f'./models/retina_stat.pt')\n",
    "        \n",
    "    else:\n",
    "        torch.save(retinanet,'./models/retina_final.pt')\n",
    "        torch.save(retinanet.state_dict(), f'./models/retina_stat.pt')\n",
    "    print('Model 저장 및 학습 및 검증 종료')\n",
    "    retinanet.eval()\n",
    "    return class_AP #mAP, AP저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a90296e-6fd7-402b-8aa9-d2f6e20dd0d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_50 backbone 사용하고, 1번 반복하여 학습합니다\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "train coco build, valid coco bild\n",
      "dataloader build success\n",
      "총 클래스 개수 2\n",
      "총 데이터 80\n",
      "dataloader iteration 20\n",
      "Num training images: 80\n",
      "Train start\n",
      "epoch 1 start\n",
      "Model학습 시작\n",
      "1 학습 완료\n",
      "Start Evaluating val datset\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.18s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "2\n",
      "category0_Background : -1.0\n",
      "category1_halibut : 0.04934376570573836\n",
      "(all categories) mAP : 0.02467188285286918\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\n",
      "2\n",
      "category0_Background : -1.0\n",
      "category1_halibut : 0.1347109248794162\n",
      "(all categories) mAP : 0.0673554624397081\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=300 ] = 0.135\n",
      "2\n",
      "category0_Background : -1.0\n",
      "category1_halibut : 0.0069410168833433684\n",
      "(all categories) mAP : 0.0034705084416716842\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=300 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=300 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=300 ] = -1.000\n",
      "2\n",
      "category0_Background : -1.0\n",
      "category1_halibut : 0.04929949478707283\n",
      "(all categories) mAP : 0.024649747393536415\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=300 ] = 0.049\n",
      "2\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390\n",
      "2\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=200 ] = 0.393\n",
      "2\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=300 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=300 ] = -1.000\n",
      "2\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=300 ] = 0.393\n",
      "----------------------------------------\n",
      "전체 클래스 mAP:50=13.47%\n",
      "----------------------------------------\n",
      "Large 객체에 대한 mAP:50:0.95=4.93%\n",
      "----------------------------------------\n",
      "Medium 객체에 대한 mAP:50:0.95=-100.0%\n",
      "----------------------------------------\n",
      "Small 객체에 대한 mAP:50:0.95=-100.0%\n",
      "----------------------------------------\n",
      "Train, Evaluation 완료, 결과값 저장 중\n",
      "Model 저장 및 학습 및 검증 종료\n",
      "Elapsed Time: 33.546597480773926 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "class_AP =Retina(path=save_path,depth=50,epochs=1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed Time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f17b8ba-4a75-4d13-b919-56adcdc5dc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 클래스 [0, 1]\n",
      "예측된 클래스 [0, 1]\n",
      "예측에 사용한 이미지 개수 10\n"
     ]
    }
   ],
   "source": [
    "# 실제 카테고리 리스트\n",
    "gt_catids=class_AP.cocoGt.getCatIds()\n",
    "print('실제 클래스',gt_catids)\n",
    "#예측된 카테고리 리스트\n",
    "dt_catids=class_AP.cocoDt.getCatIds()\n",
    "print('예측된 클래스',dt_catids)\n",
    "#예측한 이미지 개수\n",
    "print(\"예측에 사용한 이미지 개수\", len(class_AP.params.imgIds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e7633-5d6b-4720-9bc9-c5006f8800e5",
   "metadata": {},
   "source": [
    "# Test Model(모델 평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c254859-3471-4135-805b-2b02e775250f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Model_test(path):\n",
    "    dataset_test = CocoDataset(data_dir=save_path+'/'+'test', set_name='test', transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "\n",
    "    # Create the model\n",
    "    retinanet_test = model_resnet50(num_classes=dataset_test.num_classes(), pretrained=True)\n",
    "\n",
    "    use_gpu = True\n",
    "\n",
    "    if use_gpu:\n",
    "        if torch.cuda.is_available():\n",
    "            retinanet_test = retinanet_test.to(device)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # stat_dict=torch.load('./model_weights/model_stat.pt',map_location=device)\n",
    "        # from collections import OrderedDict\n",
    "        # new_stat_dict=OrderedDict()\n",
    "        # for k, v in stat_dict.items():\n",
    "        #     name=k[7:]\n",
    "        #     new_stat_dict[name] = v\n",
    "        # retinanet.load_state_dict(new_stat_dict)\n",
    "\n",
    "        retinanet_test=torch.load('C:/Users/user/Desktop/project/Retina/models/retina_final.pt')\n",
    "        retinanet_test = retinanet_test.to(device)\n",
    "    else:\n",
    "        #retinanet.load_state_dict(torch.load('C:/Users/user/Desktop/project/Retina/models/retina_stat.pt'),map_location=device)\n",
    "        retinanet_test = torch.load('C:/Users/user/Desktop/project/Retina/models/retina_final.pt')\n",
    "\n",
    "    retinanet_test.training = False\n",
    "    retinanet_test.eval()\n",
    "    retinanet_test.freeze_bn()\n",
    "\n",
    "    evaluate_coco(dataset_test, retinanet_test,path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cefc2-0e44-400f-bdb8-99582629294c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
